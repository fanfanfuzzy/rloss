# rloss for A100 GPU + Ubuntu 22.04

A100 GPUå¯¾å¿œã®rlossç’°å¢ƒæ§‹ç¯‰ã‚¬ã‚¤ãƒ‰

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. åŸºæœ¬çš„ãªç’°å¢ƒæ§‹ç¯‰
```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/fanfanfuzzy/rloss.git
cd rloss/pytorch

# Dockerç’°å¢ƒã®æ§‹ç¯‰
make build

# ç’°å¢ƒãƒ†ã‚¹ãƒˆ
make test-env

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•
make run
```

### 2. Docker Composeã‚’ä½¿ç”¨ã—ãŸç’°å¢ƒæ§‹ç¯‰
```bash
# åŸºæœ¬ã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•
docker-compose up -d rloss-a100

# Jupyter Labã‚‚å«ã‚ã¦èµ·å‹•
docker-compose --profile jupyter up -d

# TensorBoardç›£è¦–ã‚‚å«ã‚ã¦èµ·å‹•
docker-compose --profile monitoring up -d
```

## ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªMakeã‚³ãƒãƒ³ãƒ‰

### åŸºæœ¬æ“ä½œ
- `make help` - åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰ä¸€è¦§è¡¨ç¤º
- `make build` - Docker imageã®ãƒ“ãƒ«ãƒ‰
- `make run` - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
- `make run-detached` - ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
- `make exec` - å®Ÿè¡Œä¸­ã‚³ãƒ³ãƒ†ãƒŠã«æ¥ç¶š
- `make stop` - ã‚³ãƒ³ãƒ†ãƒŠåœæ­¢
- `make clean` - ã‚³ãƒ³ãƒ†ãƒŠã¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã®å‰Šé™¤

### é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ
- `make test-env` - ç’°å¢ƒãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- `make setup-data` - ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
- `make download-data` - PASCAL VOC2012ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- `make status` - ã‚³ãƒ³ãƒ†ãƒŠã¨GPUçŠ¶æ…‹ç¢ºèª
- `make info` - ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º

### è¨“ç·´ãƒ»æ¨è«–
- `make train-small` - å°ç”»åƒ(40Ã—40)ç”¨è¨“ç·´
- `make train-standard` - æ¨™æº–ç”»åƒ(513Ã—513)ç”¨è¨“ç·´
- `make inference IMAGE_PATH=/path/to/image.jpg` - æ¨è«–å®Ÿè¡Œ

### é–‹ç™ºæ”¯æ´
- `make jupyter` - Jupyter Notebookèµ·å‹•
- `make monitor-gpu` - GPUä½¿ç”¨çŠ¶æ³ç›£è¦–
- `make debug` - ãƒ‡ãƒãƒƒã‚°ç”¨ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
- `make logs` - ã‚³ãƒ³ãƒ†ãƒŠãƒ­ã‚°è¡¨ç¤º

## ğŸ”§ A100æœ€é©åŒ–è¨­å®š

### CUDAè¨­å®š
- CUDA 11.8 (A100å¯¾å¿œ)
- PyTorch 2.5.1
- cuDNN 9

### ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
```bash
# ç’°å¢ƒå¤‰æ•°ã§ã®è¨­å®š
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
TORCH_USE_CUDA_DSA=1
CUDA_LAUNCH_BLOCKING=0
```

### ãƒãƒƒãƒã‚µã‚¤ã‚ºæ¨å¥¨å€¤ï¼ˆA100 40GBï¼‰
| ç”»åƒã‚µã‚¤ã‚º | æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡(æ¦‚ç®—) |
|-----------|-----------------|-------------------|
| 40Ã—40     | 128             | ~8GB              |
| 80Ã—80     | 64              | ~12GB             |
| 256Ã—256   | 32              | ~20GB             |
| 513Ã—513   | 16              | ~35GB             |

## ğŸ“Š ä½¿ç”¨ä¾‹

### å°ç”»åƒã§ã®é«˜é€Ÿè¨“ç·´
```bash
# 40Ã—40ç”»åƒã§ã®è¨“ç·´ï¼ˆA100æœ€é©åŒ–ï¼‰
make train-small

# ã¾ãŸã¯æ‰‹å‹•å®Ÿè¡Œ
docker run --rm --gpus all \
    -v $(pwd):/workspace \
    -v /data/datasets:/data/datasets \
    rloss:a100-ubuntu22.04 \
    python pytorch-deeplab_v3_plus/train_withdensecrfloss.py \
    --backbone mobilenet \
    --crop-size 64 \
    --batch-size 128 \
    --lr 0.02 \
    --epochs 100 \
    --densecrfloss 2e-9 \
    --rloss-scale 0.25
```

### å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è¨“ç·´
```bash
# 513Ã—513ç”»åƒã§ã®è¨“ç·´ï¼ˆA100ãƒ•ãƒ«æ´»ç”¨ï¼‰
make train-standard

# ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å®Ÿè¡Œ
docker run --rm --gpus all \
    -v $(pwd):/workspace \
    -v /data/datasets:/data/datasets \
    rloss:a100-ubuntu22.04 \
    python pytorch-deeplab_v3_plus/train_withdensecrfloss.py \
    --backbone resnet \
    --crop-size 513 \
    --batch-size 16 \
    --lr 0.01 \
    --epochs 120 \
    --densecrfloss 1e-9 \
    --rloss-scale 1.0
```

### Jupyter Labã§ã®é–‹ç™º
```bash
# Jupyter Labèµ·å‹•
make jupyter

# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8888 ã«ã‚¢ã‚¯ã‚»ã‚¹
```

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### GPUèªè­˜ã•ã‚Œãªã„å ´åˆï¼ˆCUDA Error 802å¯¾å¿œï¼‰

**ç—‡çŠ¶**: nvidia-smiã§GPUãŒè¦‹ãˆã‚‹ãŒã€Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§CUDA Falseã«ãªã‚‹

```bash
# 1. NVIDIA Container Toolkitã®è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ä¿®å¾©
./install_nvidia_container_toolkit.sh

# 2. Docker GPU ã‚¢ã‚¯ã‚»ã‚¹ã®ä¿®å¾©
./fix_docker_gpu_access.sh

# 3. æ‰‹å‹•ç¢ºèª
# NVIDIA Dockerãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ç¢ºèª
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu22.04 nvidia-smi

# ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã®GPUç¢ºèª
make exec
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# 4. ç’°å¢ƒãƒ†ã‚¹ãƒˆ
make test-env
```

**æ ¹æœ¬åŸå› **: nvidia-container-toolkitãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¾ãŸã¯è¨­å®šä¸å‚™

**è§£æ±ºæ‰‹é †**:
1. nvidia-container-toolkit ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
2. Docker daemon ã® nvidia runtime è¨­å®š
3. Docker ã‚µãƒ¼ãƒ“ã‚¹ã®å†èµ·å‹•
4. GPU ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ

### è‡ªå‹•ä¿®å¾©ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

A100ã‚µãƒ¼ãƒãƒ¼ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š

```bash
# åŒ…æ‹¬çš„ãªGPUä¿®å¾©ãƒ»æ¤œè¨¼
./verify_gpu_fix.sh

# ã¾ãŸã¯å€‹åˆ¥å®Ÿè¡Œ
./install_nvidia_container_toolkit.sh  # nvidia-container-toolkit ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
./fix_docker_gpu_access.sh            # Docker GPU ã‚¢ã‚¯ã‚»ã‚¹ä¿®å¾©
make test-gpu                          # GPU ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
```

### æ‰‹å‹•ç¢ºèªæ‰‹é †

```bash
# 1. ãƒ›ã‚¹ãƒˆã§ã®GPUç¢ºèª
nvidia-smi

# 2. Docker runtimeç¢ºèª
docker info | grep -i runtime

# 3. åŸºæœ¬çš„ãªCUDAã‚³ãƒ³ãƒ†ãƒŠãƒ†ã‚¹ãƒˆ
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu22.04 nvidia-smi

# 4. PyTorchã‚³ãƒ³ãƒ†ãƒŠãƒ†ã‚¹ãƒˆ
docker run --rm --gpus all pytorch/pytorch:2.5.1-cuda11.8-cudnn9-devel python -c "import torch; print(torch.cuda.is_available())"

# 5. rlossã‚³ãƒ³ãƒ†ãƒŠãƒ†ã‚¹ãƒˆ
make test-env
```

### ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼
```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™
--batch-size 8

# ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–è¨­å®š
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256
```

### ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼
```bash
# ã‚¯ãƒªãƒ¼ãƒ³ãƒ“ãƒ«ãƒ‰
make clean
make build

# è©³ç´°ãƒ­ã‚°ã§ãƒ“ãƒ«ãƒ‰
docker build --no-cache -t rloss:a100-ubuntu22.04 -f Dockerfile.a100 .
```

## ğŸ“ˆ æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆA100 40GBï¼‰

### è¨“ç·´é€Ÿåº¦ï¼ˆç§’/ã‚¨ãƒãƒƒã‚¯ï¼‰
| è¨­å®š | ãƒãƒƒãƒã‚µã‚¤ã‚º | 40Ã—40 | 256Ã—256 | 513Ã—513 |
|------|-------------|-------|---------|---------|
| MobileNet | 32/16/8 | 45s | 180s | 420s |
| ResNet50 | 16/8/4 | 90s | 360s | 840s |

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
| ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ | ç”»åƒã‚µã‚¤ã‚º | ãƒãƒƒãƒã‚µã‚¤ã‚º | GPU ãƒ¡ãƒ¢ãƒª |
|-------------|-----------|-------------|-----------|
| MobileNet | 513Ã—513 | 16 | ~28GB |
| ResNet50 | 513Ã—513 | 8 | ~35GB |
| MobileNet | 256Ã—256 | 32 | ~18GB |

## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯

- [ãƒ¡ã‚¤ãƒ³README](../README_ja.md)
- [å°ç”»åƒå¯¾å¿œã‚¹ã‚¯ãƒªãƒ—ãƒˆ](../scripts/README.md)
- [PyTorchå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://pytorch.org/docs/)
- [NVIDIA A100ä»•æ§˜](https://www.nvidia.com/en-us/data-center/a100/)

## ğŸ“ æ³¨æ„äº‹é …

1. **NVIDIA Dockerãƒ©ãƒ³ã‚¿ã‚¤ãƒ å¿…é ˆ**: A100ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯nvidia-container-toolkitãŒå¿…è¦
2. **CUDA 11.8æ¨å¥¨**: A100ã®å…¨æ©Ÿèƒ½ã‚’æ´»ç”¨ã™ã‚‹ãŸã‚
3. **ãƒ¡ãƒ¢ãƒªç®¡ç†**: å¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºä½¿ç”¨æ™‚ã¯ãƒ¡ãƒ¢ãƒªç›£è¦–ãŒé‡è¦
4. **ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹**: `/data/datasets`ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é…ç½®ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
